{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8068f3dc",
   "metadata": {},
   "source": [
    "# Demo 1: Foundation - Simple Conversational AI\n",
    "\n",
    "This notebook demonstrates the evolution from basic completion to conversational AI using Azure OpenAI.\n",
    "\n",
    "## What We'll Cover\n",
    "1. **Setup** - Initialize Azure OpenAI client with secure authentication\n",
    "2. **Single Question** - Ask about conferences to demonstrate basic capabilities\n",
    "3. **Stateless Limitation** - Show how context is lost without conversation history\n",
    "4. **Conversational Context** - Demonstrate how to maintain context across interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ec805",
   "metadata": {},
   "source": [
    "## 1. Setup: Azure OpenAI Client Configuration\n",
    "\n",
    "Following Azure best practices, we'll use environment variables for secure configuration and set up proper error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI Configuration\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4.1-nano\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "\n",
    "# Validate configuration\n",
    "if not all([AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY]):\n",
    "    raise ValueError(\"Missing required Azure OpenAI configuration. Please check your .env file.\")\n",
    "\n",
    "# Initialize Azure OpenAI client following Azure best practices\n",
    "# Using secure credential management (environment variables, not hardcoded keys)\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Azure OpenAI client initialized successfully!\")\n",
    "print(f\"üìç Endpoint: {AZURE_OPENAI_ENDPOINT}\")\n",
    "print(f\"üöÄ Model Deployment: {AZURE_OPENAI_DEPLOYMENT}\")\n",
    "print(f\"üìÖ API Version: {AZURE_OPENAI_API_VERSION}\")\n",
    "\n",
    "# Demo conference data from environment\n",
    "DEMO_CONFERENCE = os.getenv(\"DEMO_CONFERENCE_NAME\", \"AI Innovation Summit 2025\")\n",
    "DEMO_VENUE = os.getenv(\"DEMO_VENUE\", \"Tech Convention Center\")\n",
    "DEMO_DATES = os.getenv(\"DEMO_DATES\", \"March 15-17, 2025\")\n",
    "\n",
    "print(f\"\\nüéØ Demo Context: {DEMO_CONFERENCE} at {DEMO_VENUE} ({DEMO_DATES})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a88e7",
   "metadata": {},
   "source": [
    "## 2. Single Question: Basic Chat Completion\n",
    "\n",
    "Let's ask the AI about conference management to see its foundational capabilities. This demonstrates the basic completion functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to call Azure OpenAI with error handling\n",
    "def ask_ai(messages, show_full_response=False):\n",
    "    \"\"\"\n",
    "    Send messages to Azure OpenAI and return the response.\n",
    "    Includes proper error handling and retry logic following Azure best practices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT,\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        if show_full_response:\n",
    "            print(\"üîç Full API Response:\")\n",
    "            print(json.dumps(response.model_dump(), indent=2, default=str))\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error calling Azure OpenAI: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# First question about conference management\n",
    "print(\"üé§ Question 1: What are some good conferences in Europe to attend as a tech professional?\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert conference management consultant with 15+ years of experience organizing large-scale events.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are some good conferences in Europe to attend as a tech professional?\"}\n",
    "]\n",
    "\n",
    "response = ask_ai(messages)\n",
    "if response:\n",
    "    print(\"ü§ñ AI Response:\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"Failed to get response from AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b4cba",
   "metadata": {},
   "source": [
    "## 3. Follow-up Question WITHOUT Context: Demonstrating Statelessness\n",
    "\n",
    "Now let's ask a follow-up question without providing the conversation history. This will show how the AI loses context between separate requests - a key limitation we need to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e565b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question WITHOUT conversation history\n",
    "print(\"üé§ Follow-up Question (WITHOUT context): What would be the best conference to attend, given that I live in Belgium?\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Notice: We're starting fresh - no conversation history!\n",
    "messages_without_context = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert conference management consultant with 15+ years of experience organizing large-scale events.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What would be the best conference to attend, given that I live in Belgium?\"}\n",
    "]\n",
    "\n",
    "response_without_context = ask_ai(messages_without_context)\n",
    "if response_without_context:\n",
    "    print(\"ü§ñ AI Response (Without Context):\")\n",
    "    print(response_without_context)\n",
    "    print(\"\\n‚ö†Ô∏è  Notice: The AI doesn't know what 'venue capacity issue' refers to!\")\n",
    "    print(\"   It has to ask for clarification or make assumptions.\")\n",
    "else:\n",
    "    print(\"Failed to get response from AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04608966",
   "metadata": {},
   "source": [
    "## 4. Follow-up Question WITH Context: True Conversational AI\n",
    "\n",
    "Now let's demonstrate proper conversational AI by maintaining the conversation history. This is the foundation for building intelligent, context-aware systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ecd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question WITH full conversation history\n",
    "print(\"üé§ Follow-up Question (WITH context): How can I solve the venue capacity issue?\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Build conversation history - this is the key to conversational AI!\n",
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert conference management consultant with 15+ years of experience organizing large-scale events.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are some good conferences in Europe to attend as a tech professional?\"},\n",
    "    {\"role\": \"assistant\", \"content\": response},  # Include the previous AI response\n",
    "    {\"role\": \"user\", \"content\": \"What would be the best conference to attend, given that I live in Belgium?\"}  # Our follow-up question\n",
    "]\n",
    "\n",
    "response_with_context = ask_ai(conversation_history)\n",
    "if response_with_context:\n",
    "    print(\"ü§ñ AI Response (With Context):\")\n",
    "    print(response_with_context)\n",
    "    print(\"\\n‚úÖ Notice: The AI now understands we're talking about conference venue capacity!\")\n",
    "    print(\"   It can provide specific, contextual solutions.\")\n",
    "else:\n",
    "    print(\"Failed to get response from AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333e60f",
   "metadata": {},
   "source": [
    "## 5. Conversation Summary: Key Learnings\n",
    "\n",
    "Let's implement a simple conversation manager to demonstrate the evolution from stateless to stateful AI interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086504e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConversationManager:\n",
    "    \"\"\"\n",
    "    A basic conversation manager that maintains context across multiple interactions.\n",
    "    This demonstrates the foundation for more sophisticated AI systems.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        self.client = client\n",
    "        self.deployment = AZURE_OPENAI_DEPLOYMENT\n",
    "    \n",
    "    def ask(self, user_message, show_history=False):\n",
    "        \"\"\"Ask a question and maintain conversation history\"\"\"\n",
    "        # Add user message to history\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        if show_history:\n",
    "            print(\"üìù Current Conversation History:\")\n",
    "            for i, msg in enumerate(self.messages):\n",
    "                role_emoji = {\"system\": \"‚öôÔ∏è\", \"user\": \"üë§\", \"assistant\": \"ü§ñ\"}\n",
    "                print(f\"   {i+1}. {role_emoji.get(msg['role'], '‚ùì')} {msg['role']}: {msg['content'][:100]}...\")\n",
    "            print()\n",
    "        \n",
    "        try:\n",
    "            # Get AI response\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=self.messages,\n",
    "                max_tokens=1000,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            ai_response = response.choices[0].message.content\n",
    "            \n",
    "            # Add AI response to history\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "            \n",
    "            return ai_response\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_conversation_length(self):\n",
    "        \"\"\"Get the number of exchanges in the conversation\"\"\"\n",
    "        # Subtract 1 for system message, then divide by 2 (user + assistant pairs)\n",
    "        return (len(self.messages) - 1) // 2\n",
    "\n",
    "# Initialize conversation manager\n",
    "conversation = SimpleConversationManager(\n",
    "    \"You are an expert conference management consultant specializing in large-scale technology events. \"\n",
    "    f\"You're currently helping plan {DEMO_CONFERENCE} at {DEMO_VENUE}.\"\n",
    ")\n",
    "\n",
    "print(\"üéØ Interactive Conference Planning Session\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Demonstrate fluid conversation\n",
    "questions = [\n",
    "    \"What's the most critical factor for attendee satisfaction at tech conferences?\",\n",
    "    \"How would you measure that effectively?\",\n",
    "    \"What if the budget is limited to $50k for those initiatives?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\nüé§ Question {i}: {question}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    response = conversation.ask(question, show_history=(i==1))  # Show history only for first question\n",
    "    \n",
    "    if response:\n",
    "        print(\"ü§ñ AI Response:\")\n",
    "        print(response)\n",
    "        print(f\"\\nüìä Conversation length: {conversation.get_conversation_length()} exchanges\")\n",
    "    else:\n",
    "        print(\"Failed to get response\")\n",
    "\n",
    "print(f\"\\n‚úÖ Final conversation contains {len(conversation.messages)} total messages\")\n",
    "print(\"   (1 system + multiple user/assistant pairs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c4f91",
   "metadata": {},
   "source": [
    "## Key Takeaways: From Completion to Conversation\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **üîß Setup & Security**: Proper Azure OpenAI configuration using environment variables and secure credential management\n",
    "2. **üí¨ Basic Completion**: Single-turn question answering with expert system prompting\n",
    "3. **‚ö†Ô∏è Stateless Limitation**: How context is lost between separate API calls\n",
    "4. **üîÑ Conversational Context**: Maintaining conversation history for coherent multi-turn interactions\n",
    "5. **üèóÔ∏è Architecture Foundation**: Simple conversation manager as building block for complex systems\n",
    "\n",
    "*This foundation enables everything that follows!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
